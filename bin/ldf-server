#!/usr/bin/env node
/*! @license ©2013 Ruben Verborgh - Multimedia Lab / iMinds / Ghent University */

/** Standalone Linked Data Fragments Server */

var _ = require('lodash'),
    fs = require('fs'),
    path = require('path'),
    cluster = require('cluster'),
    LinkedDataFragmentsServer = require('../lib/LinkedDataFragmentsServer'),
    IndexDatasource = require('../lib/datasources/IndexDatasource');

// Parse arguments
var args = process.argv.slice(2);
if (args.length < 1 || args.length > 3 || /^--?h(elp)?$/.test(args[0])) {
  console.log('usage: server config.json [port [workers]]');
  return process.exit(1);
}
var configFile = args[0],
    config = JSON.parse(fs.readFileSync(configFile)),
    port = parseInt(args[1], 10) || 3000,
    workers = parseInt(args[2], 10) || 1;

// Start up a cluster master
if (cluster.isMaster) {
  // Create workers
  console.log('Master %d running.', process.pid);
  for (var i = 0; i < workers; i++)
    cluster.fork();

  // Respawn crashed workers
  cluster.on('listening', function (worker) {
    worker.once('exit', function (code, signal) {
      if (!worker.suicide) {
        console.log('Worker %d died with %s. Starting new worker.',
                    worker.process.pid, code || signal);
        cluster.fork();
      }
    });
  });

  // Respawn workers one by one when receiving a SIGHUP signal
  process.on('SIGHUP', function respawn() {
    console.log('Respawning workers of master %d.', process.pid);
    process.addListener('SIGHUP', respawnPending);
    process.removeListener('SIGHUP', respawn);

    // Retrieve a list of old workers that will be replaced by new ones
    var workers = Object.keys(cluster.workers).map(function (id) { return cluster.workers[id]; });
    (function respawnNext() {
      // If there are still old workers, respawn a new one
      if (workers.length) {
        // Wait until the new worker starts listening to kill the old one
        var newWorker = cluster.fork();
        newWorker.once('listening', function () {
          var worker = workers.pop();
          if (!worker)
            return newWorker.kill(), respawnNext(); // Dead workers are replaced automatically
          worker.once('exit', function () {
            console.log('Worker %d replaces killed worker %d.',
                        newWorker.process.pid, worker.process.pid);
            respawnNext();
          });
          worker.kill();
          newWorker.removeListener('exit', abort);
        });
        // Abort the respawning process if creating a new worker fails
        newWorker.on('exit', abort);
        function abort(code, signal) {
          if (!newWorker.suicide) {
            console.log('Respawning aborted because worker %d died with %s.',
                        newWorker.process.pid, code || signal);
            process.addListener('SIGHUP', respawn);
            process.removeListener('SIGHUP', respawnPending);
          }
        }
      }
      // No old workers left, so respawning has finished
      else {
        process.addListener('SIGHUP', respawn);
        process.removeListener('SIGHUP', respawnPending);
        console.log('Respawned all workers of master %d.', process.pid);
      }
    })();
    function respawnPending() { console.log('Respawning already in progress'); }
  });
}
// Start up a worker
else {
  // Configure preset URLs
  var baseURL = config.baseURL ? config.baseURL.replace(/\/?$/, '/') : '/',
      baseURLRoot = baseURL.match(/^(?:https?:\/\/[^\/]+)?/)[0],
      baseURLPath = baseURL.substr(baseURLRoot.length),
      blankNodePath = baseURLRoot ? '/.well-known/genid/' : '',
      blankNodePrefix = blankNodePath ? baseURLRoot + blankNodePath : 'genid:';

  // Create all data sources
  var datasourceConstructors = {},
      datasources = config.datasources || {}, datasourceBase = baseURLPath.substr(1),
      dereference = config.dereference || (config.dereference = {});
  for (var datasourceName in datasources) {
    var datasourceConfig = config.datasources[datasourceName];
    delete datasources[datasourceName];
    if (datasourceConfig.enabled !== false) {
      try {
        // Avoid illegal URI characters in data source path
        var datasourcePath = datasourceBase + encodeURI(datasourceName);
        datasources[datasourcePath] = datasourceConfig;
        // Retrieve the data source class and settings
        var type = datasourceConfig.type, Datasource = datasourceConstructors[type] ||
              (datasourceConstructors[type] = require(path.join('../lib/datasources/', type))),
            settings = _.defaults(datasourceConfig.settings || {}, config), datasource;
        // Set up blank-node-to-IRI translation, with dereferenceable URLs when possible
        if (!settings.blankNodePrefix) {
          settings.blankNodePrefix = blankNodePrefix + datasourcePath + '/';
          if (blankNodePath)
            dereference[blankNodePath + datasourcePath + '/'] = datasourcePath;
        }
        // Add memento
        settings.memento = datasourceConfig.memento || false;

        // Create the data source
        datasource = new Datasource(settings);
        datasourceConfig.datasource = datasource;
        datasourceConfig.url = baseURLRoot + '/' + datasourcePath + '#dataset';
        datasourceConfig.title = datasourceConfig.title || datasourceName;
      }
      catch (error) {
        delete datasources[datasourcePath];
        process.stderr.write('Could not load datasource ' + datasourceName + ': ' + error.message + '\n');
      }
    }
  }

  // Create index data source
  var indexPath = datasourceBase.replace(/\/$/, '');
  datasources[indexPath] = datasources[indexPath] || {
    url: baseURLRoot + '/' + indexPath + '#dataset',
    role: 'index',
    title: 'dataset index',
    datasource: new IndexDatasource({ datasources: datasources }),
  };

  // Set up assets
  config.assetsPath = baseURLPath + 'assets/';

  // Set up fragment routing
  var routersSettings = config.routers || ['DatasourceRouter', 'TriplePatternRouter', 'PageRouter']
                                          .map(function (type) { return { type: type }; });
  config.routers = routersSettings.map(function (router) {
    var Router = require(path.join('../lib/routers/', router.type));
    return new Router(_.defaults(router.settings || {}, config));
  });

  // Set up writers
  var writersSettings = config.writers || {
    'text/html,*/*':         { type: 'HtmlWriter' },
    'text/turtle,text/n3':   { type: 'TurtleWriter' },
    'application/trig':      { type: 'TrigWriter' },
    'application/n-triples': { type: 'NTriplesWriter' },
    'application/n-quads':   { type: 'NQuadsWriter' },
    'application/ld+json,application/json': { type: 'JsonLdWriter' },
  };
  config.writers = _.mapValues(writersSettings, function (writer) {
    var Writer = require(path.join('../lib/writers/', writer.type));
    return new Writer(_.defaults(writer.settings || {}, config));
  });

  // Set up access logging
  var loggingSettings = _.defaults(config.logging || {}, { enabled: false, file: 'access.log' });
  if (loggingSettings.enabled) {
    var accesslog;
    try { accesslog = require('access-log'); }
    catch (e) { console.error('Cannot write access log: "access-log" dependency missing'); }
    config.accesslogger = function (request, response) {
      accesslog(request, response, null, function (logEntry) {
        fs.appendFile(loggingSettings.file, logEntry + '\n', function (error) {
          error && process.stderr.write('Error when writing to access log file: ' + error);
        });
      });
    };
  }

  // Create and start server
  var server = new LinkedDataFragmentsServer(config);
  server.listen(port);
  console.log('Worker %d running on http://localhost:%d/.', process.pid, port);

  // Terminate gracefully if possible
  process.once('SIGINT', function () {
    console.log('Stopping worker', process.pid);
    server.stop();
    process.on('SIGINT', function () { process.exit(1); });
  });
}
